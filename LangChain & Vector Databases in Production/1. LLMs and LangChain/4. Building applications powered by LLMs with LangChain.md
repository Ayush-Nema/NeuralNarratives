
### **Table of contents**
- [[#Prompt use case|Prompt use case]]
- [[#Summarization chain example|Summarization chain example]]
- [[#QA chain example|QA chain example]]
- [[#References|References]]

Notebook link: [Click here](https://colab.research.google.com/drive/19ZUQouUvFZBQIwRkrAevVPe6ASBbkYax?usp=sharing)

---

LangChain streamlines managing interactions with LLMs, chaining together multiple components, and integrating additional resources, such as APIs and databases.

# Prompt use case
- A key feature of LangChain is its support for prompts, which encompasses prompt management, prompt optimization, and a generic interface for _all LLMs_. 
- The framework also provides common utilities for working with LLMs.
- `ChatPromptTemplate` is used to create a structured conversation with the AI model, making it easier to manage the flow and content of the conversation. Message prompt templates are used to construct and work with prompts, allowing us to exploit the underlying chat model's potential fully.
- System and Human prompts differ in their roles and purposes when interacting with chat models. `SystemMessagePromptTemplate` provides initial instructions, context, or data for the AI model, while `HumanMessagePromptTemplate` are messages from the user that the AI model responds to.

```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

# import os
# os.environ[“OPENAI_API_KEY”] = "..."
chat = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

template = "You are an assistant that helps users find information about movies."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template = "Find information about the movie {movie_title}."
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

response = chat(chat_prompt.format_prompt(movie_title="Inception").to_messages())
print(response.content)
```

Output
```
Inception is a 2010 science fiction action film directed by Christopher Nolan. The film stars Leonardo DiCaprio, Ken Watanabe, Joseph Gordon-Levitt, Ellen Page, Tom Hardy, Dileep Rao, Cillian Murphy, Tom Berenger, and Michael Caine. The plot follows a professional thief who steals information by infiltrating the subconscious of his targets. He is offered a chance to have his criminal history erased as payment for the implantation of another person's idea into a target's subconscious. The film was a critical and commercial success, grossing over $829 million worldwide and receiving numerous accolades, including four Academy Awards.
```
Using the `to_messages` object in LangChain allows you to convert the formatted value of a chat prompt template into a _list_ of message objects.

# Summarization chain example
- The following code will initialize the language model using `OpenAI` class with a temperature of 0 - because we want deterministic output. 
- The `load_summarize_chain` function accepts an instance of the language model and returns a pre-built summarization chain. 
- The `PyPDFLoader` class is responsible for loading PDF files and converting them into a format suitable for processing by LangChain.

```ad-note
You need to install the `pypdf` package to run the following code. Although it is highly recommended to install the latest versions of this package, the codes have been tested on version `3.10.0`.
```

```python
# Import necessary modules
from langchain import OpenAI, PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.document_loaders import PyPDFLoader

# Initialize language model
llm = OpenAI(model_name="text-davinci-003", temperature=0)

# Load the summarization chain
summarize_chain = load_summarize_chain(llm)

# Load the document using PyPDFLoader
document_loader = PyPDFLoader(file_path="path/to/your/pdf/file.pdf")
document = document_loader.load()

# Summarize the document
summary = summarize_chain(document)
print(summary['output_text'])
```

Output
```
This document provides a summary of useful Linux commands for starting and stopping, accessing and mounting file systems, finding files and text within files, the X Window System, moving, copying, deleting and viewing files, installing software, user administration, little known tips and tricks, configuration files and what they do, file permissions, X shortcuts, printing, and a link to an official Linux pocket protector.
```

# QA chain example
We can also use LangChain to manage prompts for asking general questions from the LLMs. These models are proficient in addressing fundamental inquiries. Nevertheless, it is crucial to remain mindful of the potential issue of hallucinations, where the models may generate non-factual information. To address this concern, we will later introduce the Retrieval chain as a means to overcome this problem.
```python
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms import OpenAI

prompt = PromptTemplate(template="Question: {question}\nAnswer:", input_variables=["question"])

llm = OpenAI(model_name="text-davinci-003", temperature=0)
chain = LLMChain(llm=llm, prompt=prompt)
```

- We define a custom prompt template by creating an instance of the `PromptTemplate` class. 
- The template string contains a placeholder `{question}` for the input question, followed by a newline character and the "Answer:" label. 
- The `input_variables` argument is set to the list of available placeholders in the prompt (like a question in this case) to indicate the name of the variable that the chain will replace in the template`.run()` method.
- We then instantiate an OpenAI model named `text-davinci-003` with a temperature of 0. The `OpenAI` class is used to create the instance, and the `model_name` and `temperature` arguments are provided. 
- Finally, we create a question-answering chain using the `LLMChain` class.
- The class constructor takes two arguments: `llm`, which is the instantiated OpenAI model, and `prompt`, which is the custom prompt template we defined earlier.

```python
chain.run("what is the meaning of life?")
```
```
'The meaning of life is subjective and can vary from person to person. For some, it may be to find happiness and fulfillment, while for others it may be to make a difference in the world. Ultimately, the meaning of life is up to each individual to decide.’
```
LangChain's support for **chain sequences** also allows developers to create more complex applications with multiple calls to LLMs or other utilities. These chains can serve various purposes: personal assistants, chatbots, querying tabular data, interacting with APIs, extraction, evaluation, and summarization.


# References
1. [LangChain main page](https://pypi.org/project/langchain/)
2. [A complete guide to LangChain](https://notes.aimodels.fyi/a-complete-guide-to-langchain-building-powerful-applications-with-large-language-models/)

